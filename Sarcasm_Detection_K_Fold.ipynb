{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "id": "VFQs6P04bZKG"
   },
   "source": [
    "#unzip the data \n",
    "import zipfile\n",
    "# Unzip the downloaded file\n",
    "zip_ref = zipfile.ZipFile(\"/content/Sarcasm_Headlines_Dataset.json.zip\", \"r\")\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ldf-l--ODtZX"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "efELQ_fuELmi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tfbert\\lib\\site-packages\\pyarrow\\compute.py:198: RuntimeWarning: Python binding for CumulativeSumOptions not exposed\n",
      "  .format(class_name), RuntimeWarning)\n",
      "E:\\anaconda\\envs\\tfbert\\lib\\site-packages\\pyarrow\\compute.py:198: RuntimeWarning: Python binding for RankOptions not exposed\n",
      "  .format(class_name), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('Sarcasm_Headlines_Dataset.json',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "yq4W7FWMERcx",
    "outputId": "9196cf55-7662-47da-fa2f-e1bf5427f699"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Z55RJX64ETae",
    "outputId": "3f7f65b1-92f6-4fbe-8394-118bff2581fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['article_link'], axis=1)#Droping the article_link coloum \n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6jQNtRfXEVp9"
   },
   "outputs": [],
   "source": [
    "X = df['headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nel-HKIfEh0f",
    "outputId": "06c80c64-ce7b-4d59-d99c-a3b7557b33b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        former versace store clerk sues over secret 'b...\n",
       "1        the 'roseanne' revival catches up to our thorn...\n",
       "2        mom starting to fear son's web series closest ...\n",
       "3        boehner just wants wife to listen, not come up...\n",
       "4        j.k. rowling wishes snape happy birthday in th...\n",
       "                               ...                        \n",
       "26704                 american politics in moral free-fall\n",
       "26705                              america's best 20 hikes\n",
       "26706                                reparations and obama\n",
       "26707    israeli ban targeting boycott supporters raise...\n",
       "26708                    gourmet gifts for the foodie 2014\n",
       "Name: headline, Length: 26709, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7VsxzRKgEjW-"
   },
   "outputs": [],
   "source": [
    "Y = df['is_sarcastic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BtveFya3Etgc",
    "outputId": "6a6f2842-3052-458a-f846-c97f58a29312"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        1\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "26704    0\n",
       "26705    0\n",
       "26706    0\n",
       "26707    0\n",
       "26708    0\n",
       "Name: is_sarcastic, Length: 26709, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cebHlFuRE3Ms"
   },
   "outputs": [],
   "source": [
    "import tensorflow  as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "eMrl1-rJEuoz"
   },
   "outputs": [],
   "source": [
    "# Setup text vectorization with custom variables\n",
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 10 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FkRtMOcSE0R2"
   },
   "outputs": [],
   "source": [
    "text_vectorizer.adapt(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2SzGB3wHF0x-",
    "outputId": "6964dc01-9b6c-4f0a-99b6-d1ac6835ab0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x21d140cfc48>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                             output_dim=128, # set size of embedding vector\n",
    "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
    "                             input_length=max_length, # how long is each input\n",
    "                             name=\"embedding_1\") \n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-sNT-O-iBg_"
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XrS1YBJuF6Tz"
   },
   "outputs": [],
   "source": [
    "#functional Aip \n",
    "#model creation\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "Inputs =  layers.Input(shape=(1,),dtype='string')\n",
    "x = text_vectorizer(Inputs)\n",
    "x = embedding(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dense(3,activation='relu')(x)\n",
    "#x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
    "Dense_model = tf.keras.Model(Inputs,outputs,name='Dens_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QYz8_0EqGBBa"
   },
   "outputs": [],
   "source": [
    "#model compile \n",
    "Dense_model.compile(loss=\"binary_crossentropy\",\n",
    "                    optimizer =tf.keras.optimizers.Adam(),\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oOpdkaj2GYre",
    "outputId": "c22481e3-f343-457f-b0dd-c3f8524b7254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "557/557 [==============================] - 3s 3ms/step - loss: 0.4697 - accuracy: 0.7853\n",
      "Epoch 2/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.2671 - accuracy: 0.8925\n",
      "Epoch 3/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.1959 - accuracy: 0.9252\n",
      "Epoch 4/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.1531 - accuracy: 0.9455\n",
      "Epoch 5/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.1234 - accuracy: 0.9552\n",
      "Epoch 6/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.1026 - accuracy: 0.9639\n",
      "Epoch 7/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0847 - accuracy: 0.9703\n",
      "Epoch 8/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0710 - accuracy: 0.9752\n",
      "Epoch 9/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0589 - accuracy: 0.9800\n",
      "Epoch 10/30\n",
      "557/557 [==============================] - 1s 3ms/step - loss: 0.0512 - accuracy: 0.9820\n",
      "Epoch 11/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0434 - accuracy: 0.9848\n",
      "Epoch 12/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0376 - accuracy: 0.9872\n",
      "Epoch 13/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0329 - accuracy: 0.9885\n",
      "Epoch 14/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0275 - accuracy: 0.9909\n",
      "Epoch 15/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0250 - accuracy: 0.9911\n",
      "Epoch 16/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0226 - accuracy: 0.9922\n",
      "Epoch 17/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0207 - accuracy: 0.9922\n",
      "Epoch 18/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0188 - accuracy: 0.9924\n",
      "Epoch 19/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0169 - accuracy: 0.9936\n",
      "Epoch 20/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0156 - accuracy: 0.9940\n",
      "Epoch 21/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0147 - accuracy: 0.9941\n",
      "Epoch 22/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0140 - accuracy: 0.9946\n",
      "Epoch 23/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0121 - accuracy: 0.9953\n",
      "Epoch 24/30\n",
      "557/557 [==============================] - 2s 4ms/step - loss: 0.0124 - accuracy: 0.9949\n",
      "Epoch 25/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0118 - accuracy: 0.9952\n",
      "Epoch 26/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0115 - accuracy: 0.9951\n",
      "Epoch 27/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0096 - accuracy: 0.9958\n",
      "Epoch 28/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0092 - accuracy: 0.9960\n",
      "Epoch 29/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0104 - accuracy: 0.9956\n",
      "Epoch 30/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0100 - accuracy: 0.9956\n",
      "Epoch 1/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.4793 - accuracy: 0.8757\n",
      "Epoch 2/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.2200 - accuracy: 0.9165\n",
      "Epoch 3/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.1717 - accuracy: 0.9304\n",
      "Epoch 4/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.1401 - accuracy: 0.9405\n",
      "Epoch 5/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.1165 - accuracy: 0.9501\n",
      "Epoch 6/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0984 - accuracy: 0.9572\n",
      "Epoch 7/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0845 - accuracy: 0.9618\n",
      "Epoch 8/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0744 - accuracy: 0.9659\n",
      "Epoch 9/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0665 - accuracy: 0.9685\n",
      "Epoch 10/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0610 - accuracy: 0.9700\n",
      "Epoch 11/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0569 - accuracy: 0.9711\n",
      "Epoch 12/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0531 - accuracy: 0.9721\n",
      "Epoch 13/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0494 - accuracy: 0.9741\n",
      "Epoch 14/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0480 - accuracy: 0.9744\n",
      "Epoch 15/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0460 - accuracy: 0.9752\n",
      "Epoch 16/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0448 - accuracy: 0.9760\n",
      "Epoch 17/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0443 - accuracy: 0.9761\n",
      "Epoch 18/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0431 - accuracy: 0.9762\n",
      "Epoch 19/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0429 - accuracy: 0.9765\n",
      "Epoch 20/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0419 - accuracy: 0.9766\n",
      "Epoch 21/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0421 - accuracy: 0.9762\n",
      "Epoch 22/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0414 - accuracy: 0.9765\n",
      "Epoch 23/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0412 - accuracy: 0.9766\n",
      "Epoch 24/30\n",
      "557/557 [==============================] - 1s 3ms/step - loss: 0.0403 - accuracy: 0.9770\n",
      "Epoch 25/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0398 - accuracy: 0.9773\n",
      "Epoch 26/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0400 - accuracy: 0.9770\n",
      "Epoch 27/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0392 - accuracy: 0.9775\n",
      "Epoch 28/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0391 - accuracy: 0.9773\n",
      "Epoch 29/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0393 - accuracy: 0.9773\n",
      "Epoch 30/30\n",
      "557/557 [==============================] - 1s 3ms/step - loss: 0.0380 - accuracy: 0.9780\n",
      "Epoch 1/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.3170 - accuracy: 0.9056\n",
      "Epoch 2/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.1278 - accuracy: 0.9373\n",
      "Epoch 3/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0917 - accuracy: 0.9498\n",
      "Epoch 4/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0764 - accuracy: 0.9556\n",
      "Epoch 5/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0676 - accuracy: 0.9599\n",
      "Epoch 6/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0621 - accuracy: 0.9625\n",
      "Epoch 7/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0587 - accuracy: 0.9636\n",
      "Epoch 8/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0561 - accuracy: 0.9648\n",
      "Epoch 9/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0544 - accuracy: 0.9656\n",
      "Epoch 10/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0536 - accuracy: 0.9659\n",
      "Epoch 11/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0529 - accuracy: 0.9661\n",
      "Epoch 12/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0519 - accuracy: 0.9666\n",
      "Epoch 13/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0516 - accuracy: 0.9664\n",
      "Epoch 14/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0509 - accuracy: 0.9672\n",
      "Epoch 15/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0507 - accuracy: 0.9670\n",
      "Epoch 16/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0501 - accuracy: 0.9673\n",
      "Epoch 17/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0502 - accuracy: 0.9674\n",
      "Epoch 18/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0495 - accuracy: 0.9677\n",
      "Epoch 19/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0497 - accuracy: 0.9676\n",
      "Epoch 20/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0495 - accuracy: 0.9678\n",
      "Epoch 21/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0492 - accuracy: 0.9679\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0491 - accuracy: 0.9677\n",
      "Epoch 23/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0490 - accuracy: 0.9680\n",
      "Epoch 24/30\n",
      "557/557 [==============================] - 1s 3ms/step - loss: 0.0490 - accuracy: 0.9678\n",
      "Epoch 25/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0495 - accuracy: 0.9679\n",
      "Epoch 26/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0487 - accuracy: 0.9680\n",
      "Epoch 27/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0488 - accuracy: 0.9678\n",
      "Epoch 28/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0484 - accuracy: 0.9684\n",
      "Epoch 29/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0483 - accuracy: 0.9682\n",
      "Epoch 30/30\n",
      "557/557 [==============================] - 2s 3ms/step - loss: 0.0483 - accuracy: 0.9681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_split=3\n",
    "\n",
    "for train_index,test_index in KFold(n_split).split(X):\n",
    "  x_train,x_test=X[train_index],X[test_index]\n",
    "  y_train,y_test=Y[train_index],Y[test_index]\n",
    "\n",
    "  Dense_model.fit(x_train, y_train,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uIPEnVmGbi5G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = Dense_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9948210e-01]\n",
      " [9.9999905e-01]\n",
      " [4.5431394e-04]\n",
      " ...\n",
      " [1.1259835e-04]\n",
      " [3.6183323e-10]\n",
      " [1.6890378e-10]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Get mean pred probs for 3 models\n",
    "baseline_pred_probs = np.max(Dense_model.predict(x_test), axis=1) # get the prediction probabilities from baseline model\n",
    "predictions=tf.round(tf.squeeze(baseline_pred_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[9.9948210e-01 9.9999905e-01 4.5431394e-04 ... 1.1259835e-04 3.6183323e-10\n",
      " 1.6890378e-10], shape=(8903,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.squeeze(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGJuwNkYG5Dh",
    "outputId": "761e36ad-8be6-40d4-f910-6a689e8439e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 1s 2ms/step - loss: 0.4356 - accuracy: 0.9134\n",
      "Model evaluation  [0.43564096093177795, 0.9133999943733215]\n"
     ]
    }
   ],
   "source": [
    "print('Model evaluation ',Dense_model.evaluate(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8S0RajcJcV7",
    "outputId": "0419eb66-8d0c-4f33-9ffb-e5e062b301ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557/557 [==============================] - 1s 2ms/step - loss: 0.0478 - accuracy: 0.9686\n",
      "Model evaluation  [0.04775463044643402, 0.9686061143875122]\n"
     ]
    }
   ],
   "source": [
    "print('Model evaluation ',Dense_model.evaluate(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "8jE_Wp5QJlwp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9023432552248257\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"F1 Score: {}\".format(f1_score(y_test,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92      5037\n",
      "           1       0.88      0.92      0.90      3866\n",
      "\n",
      "    accuracy                           0.91      8903\n",
      "   macro avg       0.91      0.91      0.91      8903\n",
      "weighted avg       0.91      0.91      0.91      8903\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sarcastic_Dense\\assets\n"
     ]
    }
   ],
   "source": [
    "Dense_model.save('sarcastic_Dense',save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26704</th>\n",
       "      <td>american politics in moral free-fall</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26705</th>\n",
       "      <td>america's best 20 hikes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26706</th>\n",
       "      <td>reparations and obama</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26707</th>\n",
       "      <td>israeli ban targeting boycott supporters raise...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26708</th>\n",
       "      <td>gourmet gifts for the foodie 2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26709 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  is_sarcastic\n",
       "0      former versace store clerk sues over secret 'b...             0\n",
       "1      the 'roseanne' revival catches up to our thorn...             0\n",
       "2      mom starting to fear son's web series closest ...             1\n",
       "3      boehner just wants wife to listen, not come up...             1\n",
       "4      j.k. rowling wishes snape happy birthday in th...             0\n",
       "...                                                  ...           ...\n",
       "26704               american politics in moral free-fall             0\n",
       "26705                            america's best 20 hikes             0\n",
       "26706                              reparations and obama             0\n",
       "26707  israeli ban targeting boycott supporters raise...             0\n",
       "26708                  gourmet gifts for the foodie 2014             0\n",
       "\n",
       "[26709 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Sarcasm Detection K-Fold.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
